{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dd21f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.llms import GooglePalm\n",
    "from langchain.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api = os.environ['GOOGLE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda58a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GooglePalm(google_api_key= api, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc25e0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HuggingFace Instrcutor Embeddings are a type of language model that can be used to generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way. They are trained on large datasets of text and code, and can be fine-tuned to perform specific tasks.\n",
      "\n",
      "Here are some of the uses of the HuggingFace Instrcutor Embeddings:\n",
      "\n",
      "* **Text generation:** You can use the HuggingFace Instrcutor Embeddings to generate different kinds of text, such as poems, code, scripts, musical pieces, and email.\n",
      "* **Translation:** You can use the HuggingFace Instrcutor Embeddings to translate languages, both from one language to another and between different dialects of the same language.\n",
      "* **Creative writing:** You can use the HuggingFace Instrcutor Embeddings to write different kinds of creative content, such as stories, poems, scripts, and songs.\n",
      "* **Answering questions:** You can use the HuggingFace Instrcutor Embeddings to ask questions and get informative answers.\n",
      "\n",
      "The HuggingFace Instrcutor Embeddings are a powerful tool that can be used to create a variety of different kinds of content. They are easy to use and can be fine-tuned to perform specific tasks. If you are looking for a language model that can be used for a variety of different purposes, the HuggingFace Instrcutor Embeddings are a great option.\n"
     ]
    }
   ],
   "source": [
    "print(llm('what is the use of huggingface instrucatorembeddings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d656f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e2449dd",
   "metadata": {},
   "source": [
    "### We are using CSVLoader to load our csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bdfc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d95947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path='codebasics_faqs.csv', source_column='prompt')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5856a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58366359",
   "metadata": {},
   "source": [
    "### Using HuggingFaceInstructorEmbeding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a447d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "embedding = HuggingFaceInstructEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c701406",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = embedding.embed_query('Upendra Is Hero I dont Know How ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54b7b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14260b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00901521",
   "metadata": {},
   "source": [
    "### Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d919cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents= data, embedding= embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d38e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb5144",
   "metadata": {},
   "source": [
    "##### now you can see in this it is giving similar answer from csv bt it is not like human interactive so we will use llm to so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd2c7478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='prompt: What is different in this course from thousands of other Power BI courses available online?\\nresponse: Most of the courses available on the internet teach you how to build x & y without any business context and do not prepare you for the real business world. This course is rather an experience in which you will learn how to use Power BI & other non-technical skills to solve a real-life business problem using analytics. Here you focus on solving a business problem and in that process learn how Power BI can be used as a tool. This is how you will do the work when you start working as a data analyst/ Business analyst/ Power BI developer in the industry. This course will prepare you for not just fetching the job but, shine in it & grow further.', metadata={'source': 'What is different in this course from thousands of other Power BI courses available online?', 'row': 36}),\n",
       " Document(page_content='prompt: I have never done programming and belong to a non-technical background. Can I take this course?\\nresponse: Yes, this is the perfect course for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in their current job or business using data.', metadata={'source': 'I have never done programming and belong to a non-technical background. Can I take this course?', 'row': 24}),\n",
       " Document(page_content='prompt: Is there any prerequisite for taking this bootcamp ?\\nresponse: Our bootcamp is specifically designed for beginners with no prior experience in this field. The only prerequisite is that you need to have a functional laptop with at least 4GB ram, an internet connection, and a thrill to learn data analysis.', metadata={'source': 'Is there any prerequisite for taking this bootcamp ?', 'row': 2}),\n",
       " Document(page_content='prompt: What is the duration of this bootcamp? How long will it last?\\nresponse: You can complete all courses in 3 months if you dedicate 2-3 hours per day.', metadata={'source': 'What is the duration of this bootcamp? How long will it last?', 'row': 8})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"what is the duration of data analytics course and how about internship?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8aa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c23368d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74dbf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm, \n",
    "                                 retriever= retriever, \n",
    "                                 input_key= \"query\", \n",
    "                                 return_source_documents= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22ef27ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 months internship after course'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"what is the duration of data analytics course and how about internship?\").get('result')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea6cdcd",
   "metadata": {},
   "source": [
    "#### see in this llm giving answers for two different questions without changing the meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27cc7ca",
   "metadata": {},
   "source": [
    "now we will give some propmts coz instead of using the given information llm also use its own genral knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "382b1d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57211cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5728494",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template= prompt_template, input_variables=['context','question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f05e69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm, \n",
    "                                 retriever= retriever, \n",
    "                                 input_key= \"query\", \n",
    "                                 return_source_documents= True,chain_type_kwargs={\"prompt\":prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d7f3d1",
   "metadata": {},
   "source": [
    "## Now we are deploying it using Streamlit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be2768ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? response: I don't have any cola.\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('can i have some cola').get('result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f6bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faq_llm",
   "language": "python",
   "name": "faq_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
